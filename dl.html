    <!DOCTYPE html>
    <html lang="en">
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-104211566-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3J5NLYY0D4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3J5NLYY0D4');
</script>
       <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Remmy A. M. Zen - Deep Learning Resources</title>
	<style>
		li {
			padding:5px;
		}
		.spoiler {
		  -webkit-transition: height .7s ease-out;
		  transition: height .7s ease-out;
			color:#fff;
		}
		.spoiler-content {
		

		}
		.btn-spoiler a {
			text-decoration:none;
			color:#fff;
		  	margin: 2px;
		  	padding: 2px;
		}

		.btn-spoiler a:link
		{
		    text-decoration: none;
			color:#fff;
		}
		.btn-spoiler a:visited
		{
		    text-decoration: none;
			color:#fff;
		}
		.btn-spoiler a:hover
		{
		    text-decoration: none;
			color:#fff;
		}
		
		.btn-spoiler a:active
		{
		    text-decoration: none;
			color:#fff;
		}

		.btn-spoiler {
		  /* width: 4em;
		  height: 1.6em; */
		  background-color: rgba(35,172,27,.72);
		  display: inline-block;
		  border-radius: 5px;
		  cursor: pointer;
		  -webkit-box-shadow: 0 0 1px 1px #4b3d3d;
		  box-shadow: 0 0 1px 1px #4b3d3d
		}

		.btn-spoiler div {
		  color: #fff;
		  position: relative;
		  left: .45em;
		  top: .1em
		}

		.btn-spoiler-active { background-color: transparent }

		.btn-spoiler-active div {
		  color: #000;
		  margin-left: 0.55em
		}



	</style>    

        <!-- Bootstrap -->
        <link rel="stylesheet" type="text/css" href="assets/css/bootstrap.min.css">
        
        <!-- Main Style -->
        <link rel="stylesheet" type="text/css" href="assets/css/main.css">

        <!-- Responsive Style -->
        <link rel="stylesheet" type="text/css" href="assets/css/responsive.css">

        <!--Icon Fonts-->
        <link rel="stylesheet" media="screen" href="assets/fonts/font-awesome/font-awesome.min.css" />

        <!-- Extras -->
        <link rel="stylesheet" type="text/css" href="assets/extras/animate.css">
        <link rel="stylesheet" type="text/css" href="assets/extras/lightbox.css">


        <!-- jQuery Load -->
	    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
          <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

      </head>

    <body>
    <!-- Nav Menu Section -->
    <!--<div class="logo-menu">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation" data-spy="affix" data-offset-top="50">
      <div class="container">
        <div class="navbar-header col-md-3">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>

        <div class="collapse navbar-collapse" id="navbar">
			<ul class="nav navbar-nav col-md-9 pull-right">
			<li  class="active"><a href="index.html">&nbsp;&nbsp;Home&nbsp;&nbsp;</a></li>
			<li><a href="about.html">&nbsp;&nbsp;About&nbsp;&nbsp;</a></li>
			<li><a href="work.html">&nbsp;&nbsp;Work&nbsp;&nbsp;</a></li>
			<li><a href="experience.html">&nbsp;&nbsp;Experience&nbsp;&nbsp;</a></li>
			</ul>
        </div>
      </div>
    </nav>
    </div>-->
    <!-- Nav Menu Section End -->
    <section id="contact">
    <div class="container" style="margin-top:-5%">
    <div class="row">
    <h1 class="title">Deep Learning Resources</h1>
    <!--<h4 class="subtitle" style="font-size:12pt;">PhD Student at
	<a href="http://www.comp.nus.edu.sg">School of Computing</a>,  
	<a href="http://www.nus.edu.sg">National University of Singapore</a></h4>
	-->	
	<br/>

    <center>
	<div class="btn-spoiler" style="background-color:#4285f4;margin:5px"><a href="#book">Book</a></div>
	<div class="btn-spoiler" style="background-color:#4285f4;margin:5px"><a href="#survey">Survey</a></div>
	<div class="btn-spoiler" style="background-color:#4285f4;margin:5px"><a href="#architecture">Architecture</a></div>
	<div class="btn-spoiler" style="background-color:#4285f4;margin:5px"><a href="#application">Application</a></div>
	<div class="btn-spoiler" style="background-color:#4285f4;margin:5px"><a href="#library">Library</a></div>
    </center>
    <div class="col-md-12 col-sm-12">
	<h3 id="book" name="book">Book</h3>
	<ul>
		<li>Goodfellow, I., Bengio, Y., and Courville, A. Deep Learning. MIT Press, 2016. 
		    <a href="http://www.deeplearningbook.org/">[Link]</a>
		</li>
		<li>Nielsen, M. A. Neural Networks and Deep Learning. Determination Press, 2015. 
		    <a href="http://neuralnetworksanddeeplearning.com/">[Link]</a>
		</li>
		<li>Epelbaum, T. Deep Learning: Technical Introduction. arXiv preprint, 2017.  
		    <a href="https://arxiv.org/abs/1709.01412">[Link]</a>
		</li>
	</ul>
	
	<h3 id="survey" name="survey">Survey</h3>    
	<ul>
		<li>LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. Nature 521, 7553 (2015), 436–444. 
		    <a href="http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf">[Link]</a>
		</li>
		<li>Schmidhuber, J. Deep learning in neural networks: An overview. Neural networks 61 (2015), 85–117.
		    <a href="http://www.sciencedirect.com/science/article/pii/S0893608014002135">[Link]</a>
		</li>
		<li>Deng, L. Three classes of deep learning architectures and their applications: a tutorial survey. APSIPA transactions on signal and information processing (2012).
		    <a href="http://ai2-s2-pdfs.s3.amazonaws.com/5bd4/177440c17dad736f1e0d2227694d612f5a59.pdf">[Link]</a>
		</li>
		<li>Wang, H., Raj, B., and Xing, E. P. On the origin of deep learning. arXiv preprint arXiv:1702.07800 (2017).
		    <a href="https://arxiv.org/abs/1702.07800">[Link]</a>
		</li>
	
	</ul>


	<h3 id="architecture" name="architecture">Architecture</h3>    
	<h4 id="RNN" name="RNN">Recurrent Neural Network</h3>    
	<ul>
		<li><b>[Original-RNN]</b> Investigations on dynamic neural networks. Schmidhuber Thesis in Germany   
		    <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">[Link in Germany]</a>
		</li>
		<li><b>[Original-LSTM]</b> Hochreiter, S., and Schmidhuber, J. Long short-term memory. Neural computation 9, 8 (1997), 1735–1780. 
		    <a href="http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf">[Link]</a>
		</li>
		<li><b>[Refined-RNN-LSTM]</b> Graves, A. Generating sequences with recurrent neural networks. arXiv:1308.0850 (2013).  
		    <a href="https://arxiv.org/pdf/1308.0850.pdf">[Link]</a>
		</li>
		<li><b>[GRU]</b> Cho, K., et. al. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014). 
		    <a href="https://arxiv.org/pdf/1406.1078">[Link]</a>
		</li>
		<li><b>[Comparison]</b> Jozefowicz, R., Zaremba, W., and Sutskever, I. An empirical exploration of recurrent network architectures ̇ In Proceedings of the 32nd International Conference on Machine Learning (ICML-15) (2015), pp. 2342–2350.
		    <a href="">[Link]</a>
		</li>
		<li><b>[Seq2Seq]</b> Sutskever, I., Vinyals, O., and Le, Q. V. Sequence to sequence learning with neural networks. In Advances in neural information processing systems (2014), pp. 3104–3112.
		    <a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">[Link]</a>
		</li>
	</ul>
	<h4 id="CNN" name="CNN">Convolutional Neural Network</h3>    
	<ul>
		<li> <b>[AlexNet]</b> Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (2012), pp. 1097–1105.
		    <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">[Link]</a>
		</li>
		<li> <b>[VGGNet]</b> Simonyan, K., and Zisserman, A. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014). 
		    <a href="https://arxiv.org/pdf/1409.1556.pdf">[Link]</a>
		</li>	
		<li><b>[GoogLeNet]</b>Szegedy, C., et. al. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (2015), pp. 1–9. 
		    <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf">[Link]</a>
		</li>
		<li><b>[ResNet]</b>He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (2016), pp. 770–778. 
		    <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">[Link]</a>
		</li>
	</ul>
	<h4 id="Gen" name="Gen">Unsupervised and Deep Generative Models</h3>    
	<ul>
		<li><b>[RBM/DBN]</b> Hinton, G. E., and Salakhutdinov, R. R. Reducing the dimensionality of data with neural networks. science 313, 5786 (2006), 504–507. 
		    <a href="https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf">[Link]</a>
		</li>
		<li><b>[Autoencoder]</b> Le, Q. V. Building high-level features using large scale unsupervised learning. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on (2013), IEEE, pp. 8595–8598. 
		    <a href="https://arxiv.org/pdf/1112.6209.pdf">[Link]</a>
		</li>
		<li><b>[RNN]</b> Graves, A. Generating sequences with recurrent neural networks. arXiv:1308.0850 (2013).  
		    <a href="https://arxiv.org/pdf/1308.0850.pdf">[Link]</a>
		</li>
		<li><b>[Seq2Seq]</b> Sutskever, I., Vinyals, O., and Le, Q. V. Sequence to sequence learning with neural networks. In Advances in neural information processing systems (2014), pp. 3104–3112.
		    <a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">[Link]</a>
		</li>
		<li><b>[VAE]</b> Kingma, D. P., and Welling, M. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013). 
		    <a href="https://arxiv.org/pdf/1312.6114.pdf">[Link]</a>
		</li>
		<li><b>[GAN]</b> Goodfellow, I., et. al. Generative adversarial nets. In Advances in neural information processing systems (2014), pp. 2672–2680.  
		    <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">[Link]</a>
		</li>
		<li><b>[VAE+RNN+Attention]</b> Gregor, K., et. al. Draw: A recurrent neural network for image generation. arXiv preprint arXiv:1502.04623 (2015). 
		    <a href="https://arxiv.org/pdf/1502.04623">[Link]</a>
		</li>
		<li><b>[PixelRNN]</b> Oord, A. v. d., Kalchbrenner, N., and Kavukcuoglu, K. Pixel recurrent neural networks. arXiv preprint arXiv:1601.06759 (2016). 
		    <a href="https://arxiv.org/abs/1601.06759">[Link]</a>
		</li>
		<li><b>[PixelCNN]</b> van den Oord, A.,et al. Conditional image generation with pixelcnn decoders. In Advances in Neural Information Processing Systems (2016), pp. 4790–4798.
		    <a href="http://papers.nips.cc/paper/6527-conditional-image-generation-with-pixelcnn-decoders.pdf">[Link]</a>
		</li>
	</ul>

	<h3 id="application" name="application">Application</h3>   
	<h4>Natural Language Processing</h4> 
		<ul>
			<li><b>[Machine Translation]</b>   
			    <a href="">[Link]</a>
			</li>
			<li><b>[Sentiment Analysis]</b>   
			    <a href="">[Link]</a>
			</li>
		</ul>
	<h4>Image</h4> 
		<ul>
			<li><b>[Object Detection]</b>   
			    <a href="">[Link]</a>
			</li>
		</ul>
	
	<h4>Time Series</h4> 
		<ul>
			<li><b>[Anomaly Detection]</b>   
			    <a href="">[Link]</a>
			</li>
		</ul>


	<h3 id="library" name="library">Library</h3>    
	<ul>
		<li><b>Theano</b> (Univ Montreal) 
		    <a href="http://www.deeplearning.net/software/theano/">[Link]</a><br/>
		    Lang: Python <br/>
		    (+) Decent high-level wrappers (Keras, Lasagne)<br/>
		    (-) No multi-GPU support, bulkier
		</li>
		<li><b>Caffe</b> (UC Berkeley)
		    <a href="http://caffe.berkeleyvision.org/">[Link]</a><br/>
		    Lang: C++, interface to Python and Matlab<br/>
		    (+) Great for CNN<br/>
		    (-) Not so great for RNN
		</li>
		<li><b>TensorFlow</b> (Google)
		    <a href="https://www.tensorflow.org/">[Link]</a><br/>
		    Lang: C++, Python<br/>
		    (+) Low-level library, excellent documentation and community, visualization tool<br/>
		    (-) Slower, quite hard to debug, not too many pre-trained models
		</li>
		<li><b>Torch</b> (NYU)
		    <a href="http://torch.ch/">[Link]</a><br/>
		    Lang: C, LUA, Python (<a href="http://pytorch.org/">PyTorch</a>) <br/>
		    (+) Easier to code and debug than TensorFlow, a lot of pre-trained models<br/>
		    (-) Documentation isn't as polished as TensorFlow
		</li>
		<li><b>Keras</b>
		    <a href="https://keras.io/">[Link]</a><br/>
		    Lang: Python<br/>
		    (+) Easy to use, high-level library, run on top of Theano or Tensorflow<br/>
		    (-) Hard to debug, difficult to create new architecture
		</li>
		<li><b>Lasagne</b>
		    <a href="https://lasagne.readthedocs.io/en/latest/">[Link]</a><br/>
		    Lang: Python<br/>
		    (+) High-level library, run on top of Theano<br/>
		    (-) Hard to debug, difficult to create new architecture
		</li>
		<li><b>CNTK</b> (Microsoft)
		    <a href="https://www.microsoft.com/en-us/cognitive-toolkit/">[Link]</a><br/>
		    Lang: C++<br/>
		    <!--(+) <br/>
		    (-)-->
		</li>
		<li><b>Apache MXNet</b> (Amazon)
		    <a href="https://mxnet.incubator.apache.org/">[Link]</a><br/>
		    Lang: C++<br/>
		    <!--(+) <br/>
		    (-) -->
		</li>
		<li><b>Deeplearning4j</b> (Skymind)
		    <a href="https://deeplearning4j.org/">[Link]</a><br/>
		    Lang: Java<br/>
		    <!--(+) <br/>
		    (-) -->
		</li>
		<li><b>Chainer</b>
		    <a href="https://chainer.org/">[Link]</a><br/>
		    Lang: Python<br/>
		    <!--(+) <br/>
		    (-) --> 
		</li>
	</ul>
	*(+) and (-) are gathered from my own experience, Quora (<a href="https://www.quora.com/Which-deep-learning-framework-TensorFlow-or-PyTorch-should-I-choose">1</a>, <a href="https://www.quora.com/What-is-the-best-deep-learning-framework-I-can-use-to-classify-MRI-images-Is-Keras-suitable-for-that">2</a>), <a href="https://medium.com/@tarrysingh/how-good-is-tensorflow-as-a-deep-learning-library-and-what-other-libraries-should-one-look-out-for-782771f7c7e9">Tarry Singh</a><br/>
*Interesting analysis of framework use by academic papers (March 2017) from Alwyn Matthew <a href="https://www.quora.com/Which-deep-learning-framework-TensorFlow-or-PyTorch-should-I-choose/answer/Alwyn-Mathew-1">here</a>
<center><pre style="width:30%">% of papers 	 framework<br/>
----------------------------<br/>
    9.1          tensorflow<br/>
    7.1               caffe<br/>
    4.6              theano<br/>
    3.3               torch<br/>
    2.5               keras<br/>
    1.7          matconvnet<br/>
    1.2             lasagne<br/>
    0.5             chainer<br/>
    0.3               mxnet<br/>
    0.3                cntk<br/>
    0.2             pytorch<br/>
    0.1      deeplearning4j<br/></pre></center>
    </div>
    </div>
    </div>
	
    </section>
	<!-- About Section End -->
	<!-- Copyright Section Start-->
    <div id="copyright">
		<div class="container text-center">
			<div class="col-md-15">
				<p style="font-size:8pt">Last Updated: September 2017. Design by <a href="http://graygrids.com">GrayGrids</a></p>
			</div>
		</div>
    </div>
	<!-- Copyright Section End-->

        <!-- Bootstrap JS -->
        <script src="assets/js/jquery-min.js"></script>
	<script src="assets/js/jquery.spoiler.min.js"></script>    
	<script>$(".spoiler").spoiler();</script>
        <script src="assets/js/bootstrap.min.js"></script>

            <!-- Smooth Scroll -->
                    <!-- Smooth Scroll -->
        <script src="assets/js/smooth-scroll.js"></script>
        <script src="assets/js/lightbox.min.js"></script>

        <!-- All JS plugin Triggers -->
        <script src="assets/js/main.js"></script>



    </body>
    </html>
